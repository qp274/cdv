Virginia Eubanks stated that in face of social and welfare problems, technical tools and algorithms create this triage model that picks out and prioritize those who are deemed as “worthy of being helped”. Therefore rather than fairing out discrimination, what the algorithm does is essentially rationing resources. This may sound like the system helps limited amount of people but it helps nonetheless, however in face of inequality and discrimination, not providing support to the rest of the people IS exacerbating discrimination. There isn’t a so-called neutral perspective. I would actually argue that there is no neutral algorithms. If a system does not do good for equality, then it does harm, there is no in-between with “neutral consequences”. In the interview with Kate Crawford, Crawford also stated the data fed into AI are often biased, in order to neutralize data we should first think about what neutral looks like. For example, the majority of Chinese universities have mental health resources like school therapists and an online system to keep track of bookings. But the booking system does not distinguish between emergency or regular visits, and often times therapists are booked for months with no slots available in the near future. Students who are in need of mental health support cannot get it in time. In this case, everyone deserves mental health support equally and no one is “more eligible” than the other. Rationing resources to certain people is denying help to the others. A more appropriate model than triage is safety net, which focuses on ensuring the human rights that everyone deserves, rather than how many people could have it. With the triage logic, many necessities are treated as luxuries. The system in the example seems to be positively providing help, but is actually biased and denying help.

Eubanks touched on the topic of “accident vs. design”, which I think is a very insightful comparison. Eubanks says “to some degree intentions matter less than effect”, I think this sentence really highlights the fact that algorithms are in fact, designed, and have consequences. With the same example, the school therapist booking system by no means utilize a very complicated algorithm but is still a humanly designed technical tool. The way it is designed poses immense obstacles for those who are seeking help. To stabilize the statistics of students with mental health issues, school would limit the time slots to decrease the incoming patients. Moreover, I would argue that the intention and the purpose of a technical tool are two different things. The purpose is what the tool does, for example, providing booking timeslots of school therapists; while the intention of the tool lies within its designed logic: how does it plan to achieve its purpose? Having made this distinguishment, it is quite obvious that nothing happens on accident and everything happens because of design,
