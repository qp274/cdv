1.	Some hospitals would predict the risk each patient is facing in order to predict adequate support. They use data from insurance companies however while the “risk rating” are the same, black people have higher actual percentage of having chronical disease than white people. The data from insurance companies actually indicates who is more likely to spend more on medical resources.

2.	Government makes predictions of birth rate in order to modify birth policies.

3.	The system used in universities (eg. GRADE of the university of Texas) to rate and review applications. The system generates weighted ratings on different items (and keywords) in the applicants’ resume. However, the system is based on past applications, it could reinforce past biases. Although it is claimed to have low ‘false negative rate’, it is still liable to reject promising applicants.


The truth about preventive drugs is that for most *individuals*, they won’t do anything. But the fact that they produce a *collective benefit* makes them worth taking. When the sample size is large enough, we are bound to have all kinds of outcomes. The probability of a event occurring among the population is not exactly philosophically equivalent to the probability of a event happening on an individual. I think the birth rate prediction exemplifies how focusing on controlling/predicting the patterns in a large population can overlook its impact on individuals. In the 20th century, in order to promote the single child policy, China established a policy that the government would provide bonus after retirement for individuals who would have one single child. But just before this generation of people retire, the government retracted that retirement bonus policy. So these individuals contribute to birth control on a large picture, but when you look closer, they were the ones that have to endure the consequences of policy shifts. Similarly, in the third example that I found, on a larger scale the rating system has a low false negative rate, however it is still liable to reject an individual who are in fact qualified. The dilemma of “collective average vs. individual fate” is that the consequences of statistic uncertainties fall onto the shoulder of individuals. Therefore a statistically insignificant discrepancy of the model becomes tens of hundreds times insufferable to an individual. When designing a system whose purpose is to make decisions on *humans*, we should really think about how the consequences of statistic uncertainties would be enlarged on individuals.
